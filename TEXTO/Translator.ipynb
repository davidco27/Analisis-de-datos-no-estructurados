{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\miniconda3\\envs\\IAELPML\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-es\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_, filename_, category_, article_or_summary_,content_ = [],[],[],[],[]\n",
    "for dirname, _, filenames in os.walk('data/'):\n",
    "    for filename in filenames:\n",
    "        path = os.path.join(dirname, filename).replace(\"\\\\\",\"/\")\n",
    "        f = open(os.path.join(dirname, filename),\"r\")\n",
    "        try:\n",
    "            article = str(f.read())\n",
    "            content_.append(article)\n",
    "            path_.append(path)\n",
    "            filename_.append(filename)\n",
    "            category_.append(path.split(\"/\")[-2])\n",
    "            article_or_summary_.append(path.split(\"/\")[-3])\n",
    "        except:\n",
    "            print(\"ERROR ABRIENDO EL FICHERO\")\n",
    "            print(filename)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "      <th>article_or_summary</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/News Articles/business/001.txt</td>\n",
       "      <td>001.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>News Articles</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/News Articles/business/002.txt</td>\n",
       "      <td>002.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>News Articles</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/News Articles/business/003.txt</td>\n",
       "      <td>003.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>News Articles</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/News Articles/business/004.txt</td>\n",
       "      <td>004.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>News Articles</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/News Articles/business/005.txt</td>\n",
       "      <td>005.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>News Articles</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4443</th>\n",
       "      <td>data/Summaries/tech/397.txt</td>\n",
       "      <td>397.txt</td>\n",
       "      <td>tech</td>\n",
       "      <td>Summaries</td>\n",
       "      <td>BT is introducing two initiatives to help beat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4444</th>\n",
       "      <td>data/Summaries/tech/398.txt</td>\n",
       "      <td>398.txt</td>\n",
       "      <td>tech</td>\n",
       "      <td>Summaries</td>\n",
       "      <td>A third of them read unsolicited junk e-mail a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4445</th>\n",
       "      <td>data/Summaries/tech/399.txt</td>\n",
       "      <td>399.txt</td>\n",
       "      <td>tech</td>\n",
       "      <td>Summaries</td>\n",
       "      <td>This goes to the heart of the European project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4446</th>\n",
       "      <td>data/Summaries/tech/400.txt</td>\n",
       "      <td>400.txt</td>\n",
       "      <td>tech</td>\n",
       "      <td>Summaries</td>\n",
       "      <td>Amit Yoran was director of the National Cyber ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4447</th>\n",
       "      <td>data/Summaries/tech/401.txt</td>\n",
       "      <td>401.txt</td>\n",
       "      <td>tech</td>\n",
       "      <td>Summaries</td>\n",
       "      <td>He says that in the world of online gaming suc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4448 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     path filename  category  \\\n",
       "0     data/News Articles/business/001.txt  001.txt  business   \n",
       "1     data/News Articles/business/002.txt  002.txt  business   \n",
       "2     data/News Articles/business/003.txt  003.txt  business   \n",
       "3     data/News Articles/business/004.txt  004.txt  business   \n",
       "4     data/News Articles/business/005.txt  005.txt  business   \n",
       "...                                   ...      ...       ...   \n",
       "4443          data/Summaries/tech/397.txt  397.txt      tech   \n",
       "4444          data/Summaries/tech/398.txt  398.txt      tech   \n",
       "4445          data/Summaries/tech/399.txt  399.txt      tech   \n",
       "4446          data/Summaries/tech/400.txt  400.txt      tech   \n",
       "4447          data/Summaries/tech/401.txt  401.txt      tech   \n",
       "\n",
       "     article_or_summary                                            content  \n",
       "0         News Articles  Ad sales boost Time Warner profit\\n\\nQuarterly...  \n",
       "1         News Articles  Dollar gains on Greenspan speech\\n\\nThe dollar...  \n",
       "2         News Articles  Yukos unit buyer faces loan claim\\n\\nThe owner...  \n",
       "3         News Articles  High fuel prices hit BA's profits\\n\\nBritish A...  \n",
       "4         News Articles  Pernod takeover talk lifts Domecq\\n\\nShares in...  \n",
       "...                 ...                                                ...  \n",
       "4443          Summaries  BT is introducing two initiatives to help beat...  \n",
       "4444          Summaries  A third of them read unsolicited junk e-mail a...  \n",
       "4445          Summaries  This goes to the heart of the European project...  \n",
       "4446          Summaries  Amit Yoran was director of the National Cyber ...  \n",
       "4447          Summaries  He says that in the world of online gaming suc...  \n",
       "\n",
       "[4448 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"path\":path_, \"filename\":filename_, \"category\":category_, \"article_or_summary\":article_or_summary_,\"content\":content_}, columns=[\"path\", \"filename\", \"category\", \"article_or_summary\",\"content\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\n",
    "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    text = re.sub(r'\\n\\n', \" . \", text)\n",
    "    sentences = text.split(r' ')\n",
    "    # Keep only the first sentence\n",
    "    first_sentence = sentences[:10]\n",
    "    # Perform cleaning operations on the first sentence\n",
    "    cleaned_sentence = first_sentence.lower()\n",
    "    cleaned_sentence = re.sub(r'\\([^)]*\\)', '', cleaned_sentence)\n",
    "    cleaned_sentence = re.sub('\"', '', cleaned_sentence)\n",
    "    cleaned_sentence = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in cleaned_sentence.split(\" \")])\n",
    "    cleaned_sentence = re.sub(r\"'s\\b\", \"\", cleaned_sentence)\n",
    "    \n",
    "    return [' '.join(chunk) for chunk in chunks]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m cleaned_text \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m----> 4\u001b[0m     cleaned_text\u001b[38;5;241m.\u001b[39mappend(text_cleaner(t))\n",
      "Cell \u001b[1;32mIn[54], line 7\u001b[0m, in \u001b[0;36mtext_cleaner\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      5\u001b[0m first_sentence \u001b[38;5;241m=\u001b[39m sentences[:\u001b[38;5;241m10\u001b[39m]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Perform cleaning operations on the first sentence\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m cleaned_sentence \u001b[38;5;241m=\u001b[39m first_sentence\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m      8\u001b[0m cleaned_sentence \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m([^)]*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, cleaned_sentence)\n\u001b[0;32m      9\u001b[0m cleaned_sentence \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, cleaned_sentence)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "data = df[df[\"article_or_summary\"]==\"News Articles\"]\n",
    "cleaned_text = []\n",
    "for t in data['content']:\n",
    "    cleaned_text.append(text_cleaner(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n"
     ]
    }
   ],
   "source": [
    "translated_text = []\n",
    "i=0\n",
    "for text in cleaned_text:\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "    outputs = model.generate(input_ids=input_ids, num_beams=5, num_return_sequences=1)\n",
    "    translated_text.append(tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
    "    print(i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_final \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m:data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitular\u001b[39m\u001b[38;5;124m\"\u001b[39m:cleaned_text,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraduccion\u001b[39m\u001b[38;5;124m\"\u001b[39m:translated_text}, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitular\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraduccion\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      2\u001b[0m df_final\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/traducciones.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "df_final = pd.DataFrame({\"category\":data[\"category\"], \"titular\":cleaned_text,\"traduccion\":translated_text}, columns=[\"category\", \"titular\",\"traduccion\"])\n",
    "df_final.to_csv('data/traducciones.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('traducciones.csv')\n",
    "df = df[[\"category\", \"titular\",\"traduccion\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['traduccion'] = df['traduccion'].apply(lambda x: re.sub(r'[^a-zA-Záéíóú\\s0-9$€£ñ]', '', x.lower())).astype(str)\n",
    "df['titular'] = df['titular'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traduccion</th>\n",
       "      <th>titular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beneficios trimestrales en nosotros medios gig...</td>\n",
       "      <td>quarterly profits at us media giant timewarner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76 a 1130 millones para los tres meses</td>\n",
       "      <td>jumped 76 to 1 13bn for the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a diciembre de 639 millones de años antes</td>\n",
       "      <td>three months to december from 639m year earlier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>el dólar ha alcanzado su nivel más alto frente...</td>\n",
       "      <td>the dollar has hit its highest level against the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en casi tres meses después de que el jefe de la</td>\n",
       "      <td>euro in almost three months after the federal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6643</th>\n",
       "      <td>informáticas están seguras y ha renunciado des...</td>\n",
       "      <td>networks are safe and secure has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6644</th>\n",
       "      <td>de sólo un año en su puesto</td>\n",
       "      <td>resigned after only a year in his post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6645</th>\n",
       "      <td>los juegos de rol en</td>\n",
       "      <td>online role playing games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6646</th>\n",
       "      <td>línea consumen mucho tiempo pero</td>\n",
       "      <td>are time consuming but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6647</th>\n",
       "      <td>cautivan a los vuelos de la realidad</td>\n",
       "      <td>enthralling flights from reality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6648 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             traduccion  \\\n",
       "0     beneficios trimestrales en nosotros medios gig...   \n",
       "1                76 a 1130 millones para los tres meses   \n",
       "2             a diciembre de 639 millones de años antes   \n",
       "3     el dólar ha alcanzado su nivel más alto frente...   \n",
       "4       en casi tres meses después de que el jefe de la   \n",
       "...                                                 ...   \n",
       "6643  informáticas están seguras y ha renunciado des...   \n",
       "6644                        de sólo un año en su puesto   \n",
       "6645                               los juegos de rol en   \n",
       "6646                   línea consumen mucho tiempo pero   \n",
       "6647               cautivan a los vuelos de la realidad   \n",
       "\n",
       "                                                titular  \n",
       "0        quarterly profits at us media giant timewarner  \n",
       "1                           jumped 76 to 1 13bn for the  \n",
       "2       three months to december from 639m year earlier  \n",
       "3      the dollar has hit its highest level against the  \n",
       "4     euro in almost three months after the federal ...  \n",
       "...                                                 ...  \n",
       "6643                   networks are safe and secure has  \n",
       "6644             resigned after only a year in his post  \n",
       "6645                          online role playing games  \n",
       "6646                             are time consuming but  \n",
       "6647                   enthralling flights from reality  \n",
       "\n",
       "[6648 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_into_three(words):\n",
    "    # Calculate the size of each part\n",
    "    part_size = len(words) // 3\n",
    "    # Join the words in each part into strings\n",
    "    first_part = ' '.join(words[:part_size])\n",
    "    second_part = ' '.join(words[part_size:2*part_size])\n",
    "    third_part = ' '.join(words[2*part_size:])\n",
    "    return first_part,second_part,third_part\n",
    "\n",
    "# Apply the function to the 'traduccion' column and create a list of dictionaries\n",
    "new_rows = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    words_traduccion = re.findall(r'\\w+', row['traduccion'])\n",
    "    words_titular = re.findall(r'\\w+', row['titular'])\n",
    "    if len(words_traduccion) > 3 and len(words_titular) > 1:\n",
    "        parts_traduccion = split_into_three(words_traduccion)\n",
    "        parts_titular = split_into_three(words_titular)\n",
    "        for part_traduccion, part_titular in zip(parts_traduccion, parts_titular):\n",
    "            new_rows.append({'traduccion': part_traduccion, 'titular': part_titular})\n",
    "\n",
    "# Create a DataFrame with 'traduccion' and 'titular' columns\n",
    "df = pd.DataFrame(new_rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of English Vocabulary : 7066\n",
      "Size of Spanish Vocabulary : 8210\n"
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = Tokenizer() \n",
    "eng_tokenizer.fit_on_texts(list(df['titular']))\n",
    "\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = 10\n",
    "print('Size of English Vocabulary : %d' % eng_vocab_size)\n",
    "\n",
    "esp_tokenizer = Tokenizer() \n",
    "esp_tokenizer.fit_on_texts(list(df['traduccion']))\n",
    "\n",
    "esp_vocab_size = len(esp_tokenizer.word_index) + 1\n",
    "esp_length = 10\n",
    "print('Size of Spanish Vocabulary : %d' % esp_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sequences(tokenizer, length, lines):\n",
    "    seq = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(df[\"titular\"], df[\"traduccion\"],\n",
    "                                       test_size=0.1, random_state=0, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = encode_sequences(eng_tokenizer, eng_length, x_tr)\n",
    "trainY = encode_sequences(esp_tokenizer, esp_length, y_tr)\n",
    "\n",
    "testX = encode_sequences(eng_tokenizer, eng_length, x_val)\n",
    "testY = encode_sequences(esp_tokenizer, esp_length, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\miniconda3\\envs\\IAELPML\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "units = 256\n",
    "model = Sequential()\n",
    "model.add(Embedding(eng_vocab_size, units, input_length=eng_length, mask_zero=True))\n",
    "model.add(LSTM(units))\n",
    "model.add(RepeatVector(esp_length))\n",
    "model.add(LSTM(units, return_sequences=True))\n",
    "model.add(Dense(esp_vocab_size, activation='softmax'))\n",
    " \n",
    "rms = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510ms/step - loss: 8.8654\n",
      "Epoch 1: val_loss improved from inf to 6.24991, saving model to model.h1.Apr26v2.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 580ms/step - loss: 8.8397 - val_loss: 6.2499\n",
      "Epoch 2/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507ms/step - loss: 6.1001\n",
      "Epoch 2: val_loss improved from 6.24991 to 5.85097, saving model to model.h1.Apr26v2.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 549ms/step - loss: 6.0961 - val_loss: 5.8510\n",
      "Epoch 3/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518ms/step - loss: 5.8099\n",
      "Epoch 3: val_loss improved from 5.85097 to 5.72478, saving model to model.h1.Apr26v2.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 558ms/step - loss: 5.8091 - val_loss: 5.7248\n",
      "Epoch 4/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519ms/step - loss: 5.6699\n",
      "Epoch 4: val_loss improved from 5.72478 to 5.63663, saving model to model.h1.Apr26v2.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 561ms/step - loss: 5.6705 - val_loss: 5.6366\n",
      "Epoch 5/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - loss: 5.6200\n",
      "Epoch 5: val_loss improved from 5.63663 to 5.62300, saving model to model.h1.Apr26v2.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 594ms/step - loss: 5.6205 - val_loss: 5.6230\n",
      "Epoch 6/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step - loss: 5.5611\n",
      "Epoch 6: val_loss improved from 5.62300 to 5.60604, saving model to model.h1.Apr26v2.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 581ms/step - loss: 5.5622 - val_loss: 5.6060\n",
      "Epoch 7/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533ms/step - loss: 5.5423\n",
      "Epoch 7: val_loss improved from 5.60604 to 5.59730, saving model to model.h1.Apr26v2.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 578ms/step - loss: 5.5432 - val_loss: 5.5973\n",
      "Epoch 8/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532ms/step - loss: 5.5480\n",
      "Epoch 8: val_loss did not improve from 5.59730\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 571ms/step - loss: 5.5473 - val_loss: 5.6846\n",
      "Epoch 9/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529ms/step - loss: 5.5455\n",
      "Epoch 9: val_loss improved from 5.59730 to 5.56194, saving model to model.h1.Apr26v2.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 575ms/step - loss: 5.5444 - val_loss: 5.5619\n",
      "Epoch 10/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560ms/step - loss: 5.5003\n",
      "Epoch 10: val_loss improved from 5.56194 to 5.54386, saving model to model.h1.Apr26v2.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 622ms/step - loss: 5.5002 - val_loss: 5.5439\n",
      "Epoch 11/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554ms/step - loss: 5.4839\n",
      "Epoch 11: val_loss improved from 5.54386 to 5.53953, saving model to model.h1.Apr26v2.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 615ms/step - loss: 5.4840 - val_loss: 5.5395\n",
      "Epoch 12/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549ms/step - loss: 5.4688\n",
      "Epoch 12: val_loss improved from 5.53953 to 5.51593, saving model to model.h1.Apr26v2.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 612ms/step - loss: 5.4687 - val_loss: 5.5159\n",
      "Epoch 13/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567ms/step - loss: 5.4312\n",
      "Epoch 13: val_loss did not improve from 5.51593\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 609ms/step - loss: 5.4328 - val_loss: 5.5352\n",
      "Epoch 14/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557ms/step - loss: 5.4107\n",
      "Epoch 14: val_loss did not improve from 5.51593\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 600ms/step - loss: 5.4119 - val_loss: 5.5956\n",
      "Epoch 15/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553ms/step - loss: 5.4436\n",
      "Epoch 15: val_loss did not improve from 5.51593\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 597ms/step - loss: 5.4430 - val_loss: 5.5961\n",
      "Epoch 16/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575ms/step - loss: 5.4667\n",
      "Epoch 16: val_loss improved from 5.51593 to 5.50672, saving model to model.h1.Apr26v2.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 635ms/step - loss: 5.4644 - val_loss: 5.5067\n",
      "Epoch 17/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546ms/step - loss: 5.3999\n",
      "Epoch 17: val_loss did not improve from 5.50672\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 588ms/step - loss: 5.4006 - val_loss: 5.5197\n",
      "Epoch 18/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - loss: 5.3869\n",
      "Epoch 18: val_loss improved from 5.50672 to 5.50390, saving model to model.h1.Apr26v2.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 609ms/step - loss: 5.3876 - val_loss: 5.5039\n",
      "Epoch 19/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526ms/step - loss: 5.3593\n",
      "Epoch 19: val_loss did not improve from 5.50390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 562ms/step - loss: 5.3606 - val_loss: 5.5890\n",
      "Epoch 20/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526ms/step - loss: 5.3994\n",
      "Epoch 20: val_loss did not improve from 5.50390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 562ms/step - loss: 5.3988 - val_loss: 5.5183\n",
      "Epoch 21/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525ms/step - loss: 5.3843\n",
      "Epoch 21: val_loss did not improve from 5.50390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 561ms/step - loss: 5.3839 - val_loss: 5.5151\n",
      "Epoch 22/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527ms/step - loss: 5.3625\n",
      "Epoch 22: val_loss improved from 5.50390 to 5.49725, saving model to model.h1.Apr26v2.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 574ms/step - loss: 5.3628 - val_loss: 5.4973\n",
      "Epoch 23/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530ms/step - loss: 5.3559\n",
      "Epoch 23: val_loss did not improve from 5.49725\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 567ms/step - loss: 5.3566 - val_loss: 5.4977\n",
      "Epoch 24/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527ms/step - loss: 5.3177\n",
      "Epoch 24: val_loss did not improve from 5.49725\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 566ms/step - loss: 5.3196 - val_loss: 5.5232\n",
      "Epoch 25/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531ms/step - loss: 5.3445\n",
      "Epoch 25: val_loss improved from 5.49725 to 5.49390, saving model to model.h1.Apr26v2.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 579ms/step - loss: 5.3443 - val_loss: 5.4939\n",
      "Epoch 26/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532ms/step - loss: 5.3388\n",
      "Epoch 26: val_loss did not improve from 5.49390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 571ms/step - loss: 5.3392 - val_loss: 5.5067\n",
      "Epoch 27/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569ms/step - loss: 5.3207\n",
      "Epoch 27: val_loss did not improve from 5.49390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 612ms/step - loss: 5.3212 - val_loss: 5.5316\n",
      "Epoch 28/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614ms/step - loss: 5.3141\n",
      "Epoch 28: val_loss did not improve from 5.49390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 662ms/step - loss: 5.3149 - val_loss: 5.5551\n",
      "Epoch 29/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538ms/step - loss: 5.3024\n",
      "Epoch 29: val_loss did not improve from 5.49390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 578ms/step - loss: 5.3034 - val_loss: 5.5231\n",
      "Epoch 30/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534ms/step - loss: 5.3024\n",
      "Epoch 30: val_loss did not improve from 5.49390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 573ms/step - loss: 5.3036 - val_loss: 5.5106\n",
      "Epoch 31/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - loss: 5.2900\n",
      "Epoch 31: val_loss did not improve from 5.49390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 583ms/step - loss: 5.2907 - val_loss: 5.5098\n",
      "Epoch 32/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536ms/step - loss: 5.2963\n",
      "Epoch 32: val_loss did not improve from 5.49390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 575ms/step - loss: 5.2970 - val_loss: 5.5227\n",
      "Epoch 33/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546ms/step - loss: 5.2658\n",
      "Epoch 33: val_loss did not improve from 5.49390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 594ms/step - loss: 5.2674 - val_loss: 5.5220\n",
      "Epoch 34/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594ms/step - loss: 5.2713\n",
      "Epoch 34: val_loss did not improve from 5.49390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 635ms/step - loss: 5.2723 - val_loss: 5.5372\n",
      "Epoch 35/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551ms/step - loss: 5.2684\n",
      "Epoch 35: val_loss did not improve from 5.49390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 589ms/step - loss: 5.2696 - val_loss: 5.5140\n",
      "Epoch 36/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529ms/step - loss: 5.2789\n",
      "Epoch 36: val_loss did not improve from 5.49390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 566ms/step - loss: 5.2794 - val_loss: 5.5520\n",
      "Epoch 37/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540ms/step - loss: 5.2805\n",
      "Epoch 37: val_loss did not improve from 5.49390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 583ms/step - loss: 5.2801 - val_loss: 5.5226\n",
      "Epoch 38/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530ms/step - loss: 5.2572\n",
      "Epoch 38: val_loss did not improve from 5.49390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 568ms/step - loss: 5.2583 - val_loss: 5.5399\n",
      "Epoch 39/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537ms/step - loss: 5.2494\n",
      "Epoch 39: val_loss did not improve from 5.49390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 577ms/step - loss: 5.2501 - val_loss: 5.5616\n",
      "Epoch 40/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step - loss: 5.2527\n",
      "Epoch 40: val_loss did not improve from 5.49390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 574ms/step - loss: 5.2533 - val_loss: 5.5261\n",
      "Epoch 41/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533ms/step - loss: 5.2604\n",
      "Epoch 41: val_loss did not improve from 5.49390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 573ms/step - loss: 5.2603 - val_loss: 5.5866\n",
      "Epoch 42/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542ms/step - loss: 5.2597\n",
      "Epoch 42: val_loss did not improve from 5.49390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 582ms/step - loss: 5.2597 - val_loss: 5.5374\n",
      "Epoch 43/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552ms/step - loss: 5.2432\n",
      "Epoch 43: val_loss did not improve from 5.49390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 593ms/step - loss: 5.2435 - val_loss: 5.5428\n",
      "Epoch 44/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537ms/step - loss: 5.2417\n",
      "Epoch 44: val_loss did not improve from 5.49390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 582ms/step - loss: 5.2423 - val_loss: 5.5549\n",
      "Epoch 45/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571ms/step - loss: 5.2275\n",
      "Epoch 45: val_loss did not improve from 5.49390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 610ms/step - loss: 5.2282 - val_loss: 5.5399\n",
      "Epoch 46/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542ms/step - loss: 5.2481\n",
      "Epoch 46: val_loss did not improve from 5.49390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 584ms/step - loss: 5.2479 - val_loss: 5.5427\n",
      "Epoch 47/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537ms/step - loss: 5.2350\n",
      "Epoch 47: val_loss did not improve from 5.49390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m478s\u001b[0m 27s/step - loss: 5.2344 - val_loss: 5.5942\n",
      "Epoch 48/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569ms/step - loss: 5.2245\n",
      "Epoch 48: val_loss did not improve from 5.49390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 610ms/step - loss: 5.2250 - val_loss: 5.5597\n",
      "Epoch 49/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531ms/step - loss: 5.2248\n",
      "Epoch 49: val_loss did not improve from 5.49390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 564ms/step - loss: 5.2251 - val_loss: 5.5765\n",
      "Epoch 50/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521ms/step - loss: 5.2318\n",
      "Epoch 50: val_loss did not improve from 5.49390\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 554ms/step - loss: 5.2314 - val_loss: 5.5848\n"
     ]
    }
   ],
   "source": [
    "filename = 'model.h1.Apr26v2.keras'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# train model\n",
    "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),\n",
    "                    epochs=50, batch_size=256, validation_split = 0.2,callbacks=[checkpoint], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "665"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model(filename)\n",
    "preds = model.predict(testX.reshape((testX.shape[0],testX.shape[1])))\n",
    "preds = np.argmax(preds,axis=1)\n",
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(n, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == n:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_text = []\n",
    "for i in preds[:20]:\n",
    "    temp = []\n",
    "    for j in range(len(i)):\n",
    "        t = get_word(i[j], esp_tokenizer)\n",
    "        if j > 0:\n",
    "            if (t == get_word(i[j-1], esp_tokenizer)) or (t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)\n",
    "        else:\n",
    "            if(t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t) \n",
    "\n",
    "    preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'actual' : df[\"traduccion\"][:20], 'predicted' : preds_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beneficios trimestrales en nosotros medios gig...</td>\n",
       "      <td>un en  el  el  en la  la  a en  el   a  a en l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76 a 1130 millones para los tres meses</td>\n",
       "      <td>un en  en  el  en   la  el la  en  la el  el e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a diciembre de 639 millones de años antes</td>\n",
       "      <td>un en  en  el  en el  la  el la  en  la el  el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>el dólar ha alcanzado su nivel más alto frente...</td>\n",
       "      <td>un en  en  el  en el  la  el la  en  la el  el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en casi tres meses después de que el jefe de la</td>\n",
       "      <td>un en de la  en de en el de la  en la  en   el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>reserva federal dijo que el déficit comercial ...</td>\n",
       "      <td>un en  el  a  en la  la  los en  a   a  los en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>los propietarios de yukos gigantes rusos del p...</td>\n",
       "      <td>un en  en  el  en la  la  a en  el   a  a en l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>van a pedir al comprador de su antigua unidad</td>\n",
       "      <td>un en  en  el  en la  la  a la  el   a  a en l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>de producción que pague un préstamo de 900 mil...</td>\n",
       "      <td>un en  el  a  en la  la  los en  a   a  los en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>las vías aéreas británicas han culpado</td>\n",
       "      <td>un en  el  a  en la  la  los en  a   a  los en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a los altos precios del combustible</td>\n",
       "      <td>un en  en  el  en la  la  a la  el   a  a en l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>de una caída del 40 en los beneficios</td>\n",
       "      <td>un en  el  el  en la  la  los en  a el  a  a e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>las acciones en las bebidas y la empresa alime...</td>\n",
       "      <td>un en  el  a  en la  la  los en  a   a  los en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>domocq han aumentado de la especulación de que...</td>\n",
       "      <td>un en  en  el  en la  la  a la  el   a  a en l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>el objetivo de una toma de posesión por france...</td>\n",
       "      <td>un en  en  el  en la  la  a la  el   a  a en l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>economía japonesa tambaleó al borde</td>\n",
       "      <td>un en  el  a  en la  la  los en  a   a  los en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>de una recesión técnica en</td>\n",
       "      <td>un en  el  el  en la  la  a en  el   a  a en l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>los tres meses hasta septiembre cifras muestran</td>\n",
       "      <td>un en de la  en la en  de la en  la en  la en ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>la creación de menos puestos de trabajo de lo ...</td>\n",
       "      <td>un en  en  el  en la  la  a la  el   a  a en l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>enero pero una caída de los solicitantes de em...</td>\n",
       "      <td>un en  el  a  en la  la  los en  a   a  los en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               actual  \\\n",
       "0   beneficios trimestrales en nosotros medios gig...   \n",
       "1              76 a 1130 millones para los tres meses   \n",
       "2           a diciembre de 639 millones de años antes   \n",
       "3   el dólar ha alcanzado su nivel más alto frente...   \n",
       "4     en casi tres meses después de que el jefe de la   \n",
       "5   reserva federal dijo que el déficit comercial ...   \n",
       "6   los propietarios de yukos gigantes rusos del p...   \n",
       "7       van a pedir al comprador de su antigua unidad   \n",
       "8   de producción que pague un préstamo de 900 mil...   \n",
       "9              las vías aéreas británicas han culpado   \n",
       "10                a los altos precios del combustible   \n",
       "11              de una caída del 40 en los beneficios   \n",
       "12  las acciones en las bebidas y la empresa alime...   \n",
       "13  domocq han aumentado de la especulación de que...   \n",
       "14  el objetivo de una toma de posesión por france...   \n",
       "15                economía japonesa tambaleó al borde   \n",
       "16                         de una recesión técnica en   \n",
       "17    los tres meses hasta septiembre cifras muestran   \n",
       "18  la creación de menos puestos de trabajo de lo ...   \n",
       "19  enero pero una caída de los solicitantes de em...   \n",
       "\n",
       "                                            predicted  \n",
       "0   un en  el  el  en la  la  a en  el   a  a en l...  \n",
       "1   un en  en  el  en   la  el la  en  la el  el e...  \n",
       "2   un en  en  el  en el  la  el la  en  la el  el...  \n",
       "3   un en  en  el  en el  la  el la  en  la el  el...  \n",
       "4   un en de la  en de en el de la  en la  en   el...  \n",
       "5   un en  el  a  en la  la  los en  a   a  los en...  \n",
       "6   un en  en  el  en la  la  a en  el   a  a en l...  \n",
       "7   un en  en  el  en la  la  a la  el   a  a en l...  \n",
       "8   un en  el  a  en la  la  los en  a   a  los en...  \n",
       "9   un en  el  a  en la  la  los en  a   a  los en...  \n",
       "10  un en  en  el  en la  la  a la  el   a  a en l...  \n",
       "11  un en  el  el  en la  la  los en  a el  a  a e...  \n",
       "12  un en  el  a  en la  la  los en  a   a  los en...  \n",
       "13  un en  en  el  en la  la  a la  el   a  a en l...  \n",
       "14  un en  en  el  en la  la  a la  el   a  a en l...  \n",
       "15  un en  el  a  en la  la  los en  a   a  los en...  \n",
       "16  un en  el  el  en la  la  a en  el   a  a en l...  \n",
       "17  un en de la  en la en  de la en  la en  la en ...  \n",
       "18  un en  en  el  en la  la  a la  el   a  a en l...  \n",
       "19  un en  el  a  en la  la  los en  a   a  los en...  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IAELPML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
