{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords   \n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from keras.models import save_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from attention import AttentionLayer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import re\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_, filename_, category_, article_or_summary_,content_ = [],[],[],[],[]\n",
    "for dirname, _, filenames in os.walk('data/'):\n",
    "    for filename in filenames:\n",
    "        path = os.path.join(dirname, filename).replace(\"\\\\\",\"/\")\n",
    "        f = open(os.path.join(dirname, filename),\"r\")\n",
    "        try:\n",
    "            article = str(f.read())\n",
    "            article = article.replace(\"\\\\n\",'')\n",
    "            # Remove all excepth the alphabets\n",
    "            article = re.sub(\"[^a-zA-Z0-9]\",' ', article)\n",
    "            content_.append(article)\n",
    "            path_.append(path)\n",
    "            filename_.append(filename)\n",
    "            category_.append(path.split(\"/\")[-2])\n",
    "            article_or_summary_.append(path.split(\"/\")[-3])\n",
    "        except:\n",
    "            print(\"ERROR ABRIENDO EL FICHERO\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "      <th>article_or_summary</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/News Articles/business/001.txt</td>\n",
       "      <td>001.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>News Articles</td>\n",
       "      <td>Ad sales boost Time Warner profit  Quarterly p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/News Articles/business/002.txt</td>\n",
       "      <td>002.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>News Articles</td>\n",
       "      <td>Dollar gains on Greenspan speech  The dollar h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/News Articles/business/003.txt</td>\n",
       "      <td>003.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>News Articles</td>\n",
       "      <td>Yukos unit buyer faces loan claim  The owners ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/News Articles/business/004.txt</td>\n",
       "      <td>004.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>News Articles</td>\n",
       "      <td>High fuel prices hit BA s profits  British Air...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/News Articles/business/005.txt</td>\n",
       "      <td>005.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>News Articles</td>\n",
       "      <td>Pernod takeover talk lifts Domecq  Shares in U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4443</th>\n",
       "      <td>data/Summaries/tech/397.txt</td>\n",
       "      <td>397.txt</td>\n",
       "      <td>tech</td>\n",
       "      <td>Summaries</td>\n",
       "      <td>BT is introducing two initiatives to help beat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4444</th>\n",
       "      <td>data/Summaries/tech/398.txt</td>\n",
       "      <td>398.txt</td>\n",
       "      <td>tech</td>\n",
       "      <td>Summaries</td>\n",
       "      <td>A third of them read unsolicited junk e mail a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4445</th>\n",
       "      <td>data/Summaries/tech/399.txt</td>\n",
       "      <td>399.txt</td>\n",
       "      <td>tech</td>\n",
       "      <td>Summaries</td>\n",
       "      <td>This goes to the heart of the European project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4446</th>\n",
       "      <td>data/Summaries/tech/400.txt</td>\n",
       "      <td>400.txt</td>\n",
       "      <td>tech</td>\n",
       "      <td>Summaries</td>\n",
       "      <td>Amit Yoran was director of the National Cyber ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4447</th>\n",
       "      <td>data/Summaries/tech/401.txt</td>\n",
       "      <td>401.txt</td>\n",
       "      <td>tech</td>\n",
       "      <td>Summaries</td>\n",
       "      <td>He says that in the world of online gaming suc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4448 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     path filename  category  \\\n",
       "0     data/News Articles/business/001.txt  001.txt  business   \n",
       "1     data/News Articles/business/002.txt  002.txt  business   \n",
       "2     data/News Articles/business/003.txt  003.txt  business   \n",
       "3     data/News Articles/business/004.txt  004.txt  business   \n",
       "4     data/News Articles/business/005.txt  005.txt  business   \n",
       "...                                   ...      ...       ...   \n",
       "4443          data/Summaries/tech/397.txt  397.txt      tech   \n",
       "4444          data/Summaries/tech/398.txt  398.txt      tech   \n",
       "4445          data/Summaries/tech/399.txt  399.txt      tech   \n",
       "4446          data/Summaries/tech/400.txt  400.txt      tech   \n",
       "4447          data/Summaries/tech/401.txt  401.txt      tech   \n",
       "\n",
       "     article_or_summary                                            content  \n",
       "0         News Articles  Ad sales boost Time Warner profit  Quarterly p...  \n",
       "1         News Articles  Dollar gains on Greenspan speech  The dollar h...  \n",
       "2         News Articles  Yukos unit buyer faces loan claim  The owners ...  \n",
       "3         News Articles  High fuel prices hit BA s profits  British Air...  \n",
       "4         News Articles  Pernod takeover talk lifts Domecq  Shares in U...  \n",
       "...                 ...                                                ...  \n",
       "4443          Summaries  BT is introducing two initiatives to help beat...  \n",
       "4444          Summaries  A third of them read unsolicited junk e mail a...  \n",
       "4445          Summaries  This goes to the heart of the European project...  \n",
       "4446          Summaries  Amit Yoran was director of the National Cyber ...  \n",
       "4447          Summaries  He says that in the world of online gaming suc...  \n",
       "\n",
       "[4448 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"path\":path_, \"filename\":filename_, \"category\":category_, \"article_or_summary\":article_or_summary_,\"content\":content_}, columns=[\"path\", \"filename\", \"category\", \"article_or_summary\",\"content\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Limpiamos los textos de las noticias y los resumenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\n",
    "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definimos funciones de limpiezoa\n",
    "stop_words = set(stopwords.words('english')) \n",
    "def text_cleaner(text):\n",
    "    article = text.lower()\n",
    "    article = re.sub(r'\\([^)]*\\)', '', article)\n",
    "    article = re.sub('\"','', article)\n",
    "    article = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in article.split(\" \")])    \n",
    "    article = re.sub(r\"'s\\b\",\"\",article)\n",
    "    article = re.sub(\"[^a-zA-Z]\", \" \", article) \n",
    "    tokens = [w for w in article.split() if not w in stop_words]\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>=3:          \n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()\n",
    "def summary_cleaner(text):\n",
    "    summary = re.sub('\"','', text)\n",
    "    summary = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in summary.split(\" \")])    \n",
    "    summary = re.sub(r\"'s\\b\",\"\",summary)\n",
    "    summary = re.sub(\"[^a-zA-Z]\", \" \", summary)\n",
    "    summary = summary.lower()\n",
    "    tokens=summary.split()\n",
    "    summary=''\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                 \n",
    "            summary=summary+i+' '  \n",
    "    summary = 'sostok ' + summary + 'eostok'\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[df[\"article_or_summary\"]==\"News Articles\"]\n",
    "cleaned_text = []\n",
    "for t in data['content']:\n",
    "    cleaned_text.append(text_cleaner(t))\n",
    "data = df[df[\"article_or_summary\"]==\"Summaries\"]\n",
    "cleaned_summary = []\n",
    "for t in data['content']:\n",
    "    cleaned_summary.append(summary_cleaner(t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitamos el tamaño de las noticias. Vamos a ver cuanto puede ser el limite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El 56.160071942446045 % de las noticias tiene menos de 200 valores\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "th = 200\n",
    "for i in cleaned_text:\n",
    "    if(len(i.split()) <= th):\n",
    "        cnt=cnt+1\n",
    "print(f\"El {100*cnt/len(cleaned_text)} % de las noticias tiene menos de {th} valores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lo mismo pero para los resumenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El 0.49460431654676257 % de los resumenes tiene menos de 50 valores\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "th = 50\n",
    "for i in cleaned_summary:\n",
    "    if(len(i.split()) <= th):\n",
    "        cnt=cnt+1\n",
    "print(f\"El {100*cnt/len(cleaned_text)} % de los resumenes tiene menos de {th} valores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente fijamos longitud maxima de noticias a 350 y de resumenes a 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_len=350\n",
    "max_summary_len = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separamos en train y test (85-15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(np.array(cleaned_text), np.array(cleaned_summary),\n",
    "                                       test_size=0.15, random_state=0, shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vemos cuáles las palabras raras, aquellas que aparecen pocas veces. Lo suyo será quitarlas del tokenizador porque no aportan mucho.\n",
    "Hemos decidido que la definición de rara es que aparezca menos de 5 veces en total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las palabras raras son un 63.493788819875775% del total, siendo un 7.240811574505508 del texto\n"
     ]
    }
   ],
   "source": [
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "thresh=5\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(f\"Las palabras raras son un {cnt/tot_cnt*100}% del total, siendo un {(freq/tot_freq)*100} del texto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las palabras raras son un 67.19959890813882% del total, siendo un 6.675486326876537 del texto\n"
     ]
    }
   ],
   "source": [
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "thresh=5\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(f\"Las palabras raras son un {cnt/tot_cnt*100}% del total, siendo un {(freq/tot_freq)*100} del texto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizamos las noticias y los resumenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTICIAS\n",
    "\n",
    "# En el tokenizer quitamos las palabras raras\n",
    "x_tokenizer = Tokenizer(num_words=tot_cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "# Tenemos que meter el padding para las noticias cortas\n",
    "x_tr    =   pad_sequences(x_tokenizer.texts_to_sequences(x_tr) ,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_tokenizer.texts_to_sequences(x_val), maxlen=max_text_len, padding='post')\n",
    "\n",
    "# El tamaño del vocabulario\n",
    "x_voc   =  x_tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RESUMENES\n",
    "\n",
    "y_tokenizer = Tokenizer(num_words=tot_cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "# Tenemos que meter el padding para los resumenes cortos\n",
    "y_tr    =   pad_sequences(y_tokenizer.texts_to_sequences(y_tr) , maxlen=max_summary_len, padding='post')\n",
    "y_val   =   pad_sequences(y_tokenizer.texts_to_sequences(y_val) , maxlen=max_summary_len, padding='post')\n",
    "\n",
    "# El tamaño del vocabulario\n",
    "y_voc  =   y_tokenizer.num_words +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('xtokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(x_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('ytokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(y_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos el modelo de redes neuronales, formado por un encoder y un decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder. Se utilizan 3 LSTM consecutivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 200\n",
    "embedding_dim=100\n",
    "\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "\n",
    "# Capa de embeddings\n",
    "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#Lstm 1\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#Lstm 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#Lstm 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder. Usamos una capa de atención definida en el archivo attention.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "# Attention layer\n",
    "#attn_layer = AttentionLayer(name='attention_layer') \n",
    "#attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "#decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# Dense Layer\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">350</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">350</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,795,200</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">350</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">240,800</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">350</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">320,800</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,795,200</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">350</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">320,800</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">240,800</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,608,352</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">17952</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m350\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m350\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │  \u001b[38;5;34m1,795,200\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m350\u001b[0m,      │    \u001b[38;5;34m240,800\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m200\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m200\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m200\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m350\u001b[0m,      │    \u001b[38;5;34m320,800\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│                     │ \u001b[38;5;34m200\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m200\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m200\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │  \u001b[38;5;34m1,795,200\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m350\u001b[0m,      │    \u001b[38;5;34m320,800\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m200\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m200\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m200\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m240,800\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m200\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
       "│                     │ \u001b[38;5;34m200\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m200\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m3,608,352\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m17952\u001b[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,321,952</span> (31.75 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,321,952\u001b[0m (31.75 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,321,952</span> (31.75 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,321,952\u001b[0m (31.75 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definimos el modelo\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)\n",
    "filename = 'model.scratch_lstm.keras'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - loss: 9.7783\n",
      "Epoch 1: val_loss improved from inf to 8.93892, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 8s/step - loss: 9.7740 - val_loss: 8.9389\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 8.2701\n",
      "Epoch 2: val_loss improved from 8.93892 to 7.13088, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 11s/step - loss: 8.2417 - val_loss: 7.1309\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 7.2149\n",
      "Epoch 3: val_loss improved from 7.13088 to 7.01031, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 9s/step - loss: 7.2147 - val_loss: 7.0103\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 7.1407\n",
      "Epoch 4: val_loss improved from 7.01031 to 6.96930, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 9s/step - loss: 7.1408 - val_loss: 6.9693\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 7.1183 \n",
      "Epoch 5: val_loss improved from 6.96930 to 6.95166, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 12s/step - loss: 7.1181 - val_loss: 6.9517\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - loss: 7.1036\n",
      "Epoch 6: val_loss improved from 6.95166 to 6.94129, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 9s/step - loss: 7.1034 - val_loss: 6.9413\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 7.0840\n",
      "Epoch 7: val_loss improved from 6.94129 to 6.93468, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 10s/step - loss: 7.0844 - val_loss: 6.9347\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 7.0734\n",
      "Epoch 8: val_loss improved from 6.93468 to 6.93017, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 9s/step - loss: 7.0740 - val_loss: 6.9302\n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 7.0831\n",
      "Epoch 9: val_loss improved from 6.93017 to 6.92639, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 9s/step - loss: 7.0829 - val_loss: 6.9264\n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 7.0804\n",
      "Epoch 10: val_loss improved from 6.92639 to 6.92346, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 10s/step - loss: 7.0802 - val_loss: 6.9235\n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 7.0638 \n",
      "Epoch 11: val_loss improved from 6.92346 to 6.92326, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 11s/step - loss: 7.0644 - val_loss: 6.9233\n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 7.0605 \n",
      "Epoch 12: val_loss improved from 6.92326 to 6.92213, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 11s/step - loss: 7.0612 - val_loss: 6.9221\n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 7.0721 \n",
      "Epoch 13: val_loss improved from 6.92213 to 6.91998, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 11s/step - loss: 7.0720 - val_loss: 6.9200\n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 7.0409 \n",
      "Epoch 14: val_loss improved from 6.91998 to 6.91375, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 11s/step - loss: 7.0423 - val_loss: 6.9137\n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 7.0765 \n",
      "Epoch 15: val_loss improved from 6.91375 to 6.91017, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 11s/step - loss: 7.0756 - val_loss: 6.9102\n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 7.0575 \n",
      "Epoch 16: val_loss improved from 6.91017 to 6.90749, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 11s/step - loss: 7.0575 - val_loss: 6.9075\n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 7.0373 \n",
      "Epoch 17: val_loss did not improve from 6.90749\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 11s/step - loss: 7.0385 - val_loss: 6.9095\n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 7.0404 \n",
      "Epoch 18: val_loss did not improve from 6.90749\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 11s/step - loss: 7.0412 - val_loss: 6.9085\n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 7.0503 \n",
      "Epoch 19: val_loss improved from 6.90749 to 6.90059, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 11s/step - loss: 7.0503 - val_loss: 6.9006\n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 7.0495 \n",
      "Epoch 20: val_loss did not improve from 6.90059\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 11s/step - loss: 7.0494 - val_loss: 6.9056\n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 7.0390 \n",
      "Epoch 21: val_loss improved from 6.90059 to 6.89826, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 11s/step - loss: 7.0394 - val_loss: 6.8983\n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 7.0490 \n",
      "Epoch 22: val_loss improved from 6.89826 to 6.89326, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 11s/step - loss: 7.0487 - val_loss: 6.8933\n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 7.0406 \n",
      "Epoch 23: val_loss did not improve from 6.89326\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 12s/step - loss: 7.0405 - val_loss: 6.8950\n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 7.0255 \n",
      "Epoch 24: val_loss improved from 6.89326 to 6.88961, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 12s/step - loss: 7.0263 - val_loss: 6.8896\n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 7.0158 \n",
      "Epoch 25: val_loss improved from 6.88961 to 6.88568, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 12s/step - loss: 7.0168 - val_loss: 6.8857\n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - loss: 7.0255\n",
      "Epoch 26: val_loss improved from 6.88568 to 6.88504, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 8s/step - loss: 7.0258 - val_loss: 6.8850\n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 7.0309 \n",
      "Epoch 27: val_loss improved from 6.88504 to 6.88480, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 11s/step - loss: 7.0308 - val_loss: 6.8848\n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - loss: 7.0440\n",
      "Epoch 28: val_loss improved from 6.88480 to 6.88001, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 9s/step - loss: 7.0427 - val_loss: 6.8800\n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 6.9995 \n",
      "Epoch 29: val_loss improved from 6.88001 to 6.86774, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 11s/step - loss: 7.0007 - val_loss: 6.8677\n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - loss: 7.0060\n",
      "Epoch 30: val_loss did not improve from 6.86774\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 9s/step - loss: 7.0064 - val_loss: 6.8683\n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 7.0232\n",
      "Epoch 31: val_loss improved from 6.86774 to 6.85555, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 9s/step - loss: 7.0224 - val_loss: 6.8556\n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 6.9970\n",
      "Epoch 32: val_loss improved from 6.85555 to 6.84886, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 9s/step - loss: 6.9972 - val_loss: 6.8489\n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 6.9890 \n",
      "Epoch 33: val_loss improved from 6.84886 to 6.83864, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 12s/step - loss: 6.9891 - val_loss: 6.8386\n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 6.9752 \n",
      "Epoch 34: val_loss improved from 6.83864 to 6.82345, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 12s/step - loss: 6.9755 - val_loss: 6.8234\n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - loss: 6.9900\n",
      "Epoch 35: val_loss improved from 6.82345 to 6.81453, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 8s/step - loss: 6.9888 - val_loss: 6.8145\n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 6.9670\n",
      "Epoch 36: val_loss improved from 6.81453 to 6.80818, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 9s/step - loss: 6.9668 - val_loss: 6.8082\n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 6.9581\n",
      "Epoch 37: val_loss improved from 6.80818 to 6.79732, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 11s/step - loss: 6.9579 - val_loss: 6.7973\n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 6.9354 \n",
      "Epoch 38: val_loss improved from 6.79732 to 6.78866, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 11s/step - loss: 6.9361 - val_loss: 6.7887\n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 6.9343 \n",
      "Epoch 39: val_loss improved from 6.78866 to 6.78203, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 11s/step - loss: 6.9345 - val_loss: 6.7820\n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - loss: 6.9100\n",
      "Epoch 40: val_loss improved from 6.78203 to 6.77523, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 8s/step - loss: 6.9112 - val_loss: 6.7752\n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 6.9268\n",
      "Epoch 41: val_loss improved from 6.77523 to 6.76577, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 10s/step - loss: 6.9266 - val_loss: 6.7658\n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 6.8896\n",
      "Epoch 42: val_loss improved from 6.76577 to 6.76077, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 10s/step - loss: 6.8913 - val_loss: 6.7608\n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 6.8736\n",
      "Epoch 43: val_loss improved from 6.76077 to 6.75708, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 10s/step - loss: 6.8758 - val_loss: 6.7571\n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 6.8869\n",
      "Epoch 44: val_loss improved from 6.75708 to 6.74781, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 10s/step - loss: 6.8881 - val_loss: 6.7478\n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 6.8992\n",
      "Epoch 45: val_loss improved from 6.74781 to 6.74553, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 10s/step - loss: 6.8993 - val_loss: 6.7455\n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 6.8795\n",
      "Epoch 46: val_loss improved from 6.74553 to 6.74143, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 10s/step - loss: 6.8805 - val_loss: 6.7414\n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 6.9063\n",
      "Epoch 47: val_loss improved from 6.74143 to 6.73952, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 10s/step - loss: 6.9054 - val_loss: 6.7395\n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 6.8817\n",
      "Epoch 48: val_loss improved from 6.73952 to 6.73861, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 10s/step - loss: 6.8820 - val_loss: 6.7386\n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 6.8856\n",
      "Epoch 49: val_loss improved from 6.73861 to 6.72888, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 10s/step - loss: 6.8855 - val_loss: 6.7289\n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 6.8883\n",
      "Epoch 50: val_loss improved from 6.72888 to 6.72817, saving model to model.scratch_lstm.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 10s/step - loss: 6.8878 - val_loss: 6.7282\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([x_tr, y_tr[:,:-1]], \n",
    "                  y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:,1:],\n",
    "                  epochs=50,\n",
    "                  callbacks=[es,checkpoint],\n",
    "                  batch_size=128, \n",
    "                  validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:])\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word\n",
    "reverse_source_word_index=x_tokenizer.index_word\n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "#attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "#decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) \n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "encoder_model.save(\"encoder_model.h5\")\n",
    "\n",
    "# Save decoder model\n",
    "decoder_model.save(\"decoder_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "      \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index+1]\n",
    "        \n",
    "        if(sampled_token!='eostok'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
    "            newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2263,  1063,  4873,   318,  4016,  3079,  2626, 13045,  2263,\n",
       "            8,    87,   375,  2104,   318,  1243,   258,   105,  2105,\n",
       "          371,  1177,  3415,    45,   191,  3688,   243,   115, 13045,\n",
       "          180,    79,    87,   375,   815,   730,     1,  2626,   565,\n",
       "          319,  4017,   199,  1329,   232,   103,  1425,  1578,    29,\n",
       "           61,   232,  1425,   143,   225,   371,  2263,     4,  2627,\n",
       "         3569,   326,   243,   258,  2212,   909,  4017,  5889,  8367,\n",
       "          276,  3080, 16907, 16908,    79,    90,  1244,  3569,  6365,\n",
       "         8368,  2422, 16909,  2626,   331,   332,   791,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr[0].reshape(1,max_text_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News: cole faces lengthy injury lay aston villa carlton cole could six weeks knee injury striker season long loan chelsea picked knock england match holland earlier month carlton action four six weeks bad challenge said villa boss david leary able tell whether need operation maybe next week whether operation got left chelsea cole also struggled ankle problem earlier season unable rest leary shortage strikers return fitness darius vassell four months broken ankle emergence luke moore alleviated villa manager problems department \n",
      "Original summary: aston villa carlton cole could be out for six weeks with knee injury the return to fitness of darius vassell after four months out with broken ankle and the emergence of luke moore has alleviated some of the villa manager problems in that department carlton will be out of action for four to six weeks after bad challenge said villa boss david leary \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Predicted summary:  to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to\n",
      "\n",
      "\n",
      "News: ireland argentina injury time dropped goal ronan gara stole victory ireland underneath noses argentina lansdowne road saturday gara kicked ireland points two dropped goals five penalties give home side record autumn internationals impressive argentina appeared control dying seconds pumas shocked irish early try federico aramburu felipe contepomi kicked points well drilled sharper pumas played thought ireland early stages indiscipline allowed argentina leinster fly half contepomi open scoring third minute straightforward penalty mark two minutes later argentina shocked ragged ireland first try game ireland turned ball manuel contepomi broke unstructured defence feeding midfield partner aramburu sprint posts gara finally got ireland board dropped goal ninth minute contepomi rifle second penalty two minutes later playing strong wind rain ireland continued come second best tight situations turnovers began mount rugged defence gara managed land second penalty minute contepomi replied kind four minutes first half injury time second half started first ended gara rifled another penalty minute contepomi matched three minutes later upper body strength pumas never allowed ireland take control front three quarters space manoeuvre ireland rely gara boot keep touch rather contrived running plays munsterman landed two penalties one metres bring team within four points minutes clock remaining ireland chance came argentina number eight gonzalo longo yellow carded six minutes offence line gara made mistake rifled fifth penalty set tense final minutes ireland showed great composure get position allow gara thump massive drop goal complete tremendous fortuitous comeback \n",
      "Original summary: kind four minutes into first half injury time an injury time dropped goal by ronan gara stole victory for ireland from underneath the noses of argentina at lansdowne road on saturday indiscipline allowed argentina leinster fly half contepomi to open the scoring in the third minute with straightforward penalty the munsterman landed two more penalties one of them from metres to bring his team to within four points with minutes on the clock remaining but ireland showed great composure to get themselves into position to allow gara to thump over massive drop goal to complete tremendous if fortuitous comeback \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Predicted summary:  to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 2):\n",
    "    print(\"News:\",seq2text(x_tr[i]))\n",
    "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
    "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IAELPML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
